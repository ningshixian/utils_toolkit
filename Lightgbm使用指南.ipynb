{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "敲定好一组参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'auc'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参 http://www.huaxiaozhuan.com/%E5%B7%A5%E5%85%B7/lightgbm/chapters/lightgbm_usage.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 树的参数 | 含义 | 设置 |\n",
    "|--|--|--|\n",
    "| num_leaves | 叶节点的数目，控制树模型复杂度 | 小于2^{depth} |\n",
    "| min_data_in_leaf | 每个叶节点的最少样本数量 | 控制过拟合 |\n",
    "| max_depth | 树的最大深度 | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 核心参数 | 含义 | 设置 |\n",
    "|--|--|--|\n",
    "| task | 要执行的任务 | train/predict/convert_model |\n",
    "| application 或者objective 或者 app | 任务类型 | regression/binary/multiclass/xentropy/lambdarank/... |\n",
    "| boosting或者boost或者boosting_type | 基学习器模型算法 | gbdt/rf/dart/goss |\n",
    "| num_iteration或者num_tree或者 num_round或者 num_boost_round | 迭代次数 | 默认100 |\n",
    "| learning_rate | 学习率 | 默认为 0.1 |\n",
    "|num_leaves或者num_leaf | 一棵树上的叶子数 | 默认为 31 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 学习控制参数 | 含义 | 设置 |\n",
    "|--|--|--|\n",
    "| max_depth | 树模型的最大深度 | 默认值为-1 |\n",
    "| min_data_in_leaf | 一个叶子节点上包含的最少样本数量。 | 默认值为 20 |\n",
    "| feature_fraction | 如0.8 表示：在每棵树训练之前选择80% 的特征来训练 | 取值范围为[0.0,1.0]， 默认值为1.0 |\n",
    "| bagging_fraction 或者 subsample  | 如0.8 表示：在每棵树训练之前选择80% 的样本（非重复采样）来训练 | 取值范围为[0.0,1.0]， 默认值为1.0 |\n",
    "| early_stopping_round或者early_stopping  | 如果一个验证集的度量在early_stopping_round 循环中没有提升，则停止训练 | - |\n",
    "| lambda_l1 或者reg_alpha | 表示L1正则化系数。 | 默认为0 |\n",
    "| lambda_l2 或者reg_lambda | 表示L2正则化系数。 | 默认为0 |\n",
    "| min_split_gain 或者min_gain_to_split | 一个浮点数，表示执行切分的最小增益 | 默认为0 |\n",
    "| min_data_per_group | 表示每个分类组的最小数据量 用于排序任务 | 默认值为100 |\n",
    "| cat_smooth | 用于category 特征的概率平滑，降低噪声在category 特征中的影响，尤其是对于数据很少的类。 | 默认值为 10 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 度量参数 | 含义 | 设置 |\n",
    "|--|--|--|\n",
    "| metric | 度量的指标 | 对于回归问题，使用l2 ； 对于二分类问题，使用binary_logloss；对于lambdarank 问题，使用ndcg |\n",
    "| metric_freq或者'output_freq | 一个正式，表示每隔多少次输出一次度量结果 | 默认为1 |\n",
    "| train_metric 或者training_metric | 如果为True，则在训练时就输出度量结果 | 默认值为 False |\n",
    "| ndcg_at 或者 ndcg_eval_at 或者eval_at | 指定了NDCG 评估点的位置。 | 默认为1,2,3,4,5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取更好的准确率：\n",
    "\n",
    "- 使用较大的 max_bin （学习速度可能变慢）\n",
    "- 使用较小的 learning_rate 和较大的 num_iterations\n",
    "- 使用较大的 num_leaves （可能导致过拟合）\n",
    "- 使用更大的训练数据\n",
    "- 尝试 dart\n",
    "- 缓解过拟合：\n",
    "\n",
    "使用较小的 max_bin\n",
    "\n",
    "- 使用较小的 num_leaves\n",
    "- 使用 min_data_in_leaf 和 min_sum_hessian_in_leaf\n",
    "- 通过设置 bagging_fraction 和 bagging_freq 来使用 bagging\n",
    "- 通过设置 feature_fraction 来使用特征子抽样\n",
    "- 使用更大的训练数据\n",
    "- 使用 lambda_l1, lambda_l2 和 min_gain_to_split 来使用正则\n",
    "- 尝试 max_depth 来避免生成过深的树\n",
    "\n",
    "分类特征支持\n",
    "\n",
    "要想使用categorical 特征，则启用categorical_feature 参数\n",
    "- 首先要将categorical 特征的取值转换为非负整数，而且如果是连续的范围更好\n",
    "- 然后使用min_data_per_group 和 cat_smooth 去处理过拟合（当样本数较小，或者category 取值范围较大时）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.save_model('model.m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的载入与预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.Booster(model_file='./model/model.m')\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类似在xgboost中的形式\n",
    "# 自定义损失函数需要\n",
    "def loglikelood(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    preds = 1. / (1. + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1. - preds)\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "# 自定义评估函数\n",
    "def binary_error(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'error', np.mean(labels != (preds > 0.5)), False\n",
    "\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                init_model=gbm,\n",
    "                fobj=loglikelood,\n",
    "                feval=binary_error,\n",
    "                valid_sets=lgb_eval)\n",
    "\n",
    "print('用自定义的损失函数与评估标准完成第40-50轮...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optuna超参数优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    x = trial.suggest_uniform('x', -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "study.best_params  # E.g. {'x': 2.002108042}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体使用可参考《GIVE OPTUNA A SHOT!》\n",
    "https://zhuanlan.zhihu.com/p/138521995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
